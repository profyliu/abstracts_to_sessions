{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Session Planning LSC.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = data['Abstract #']\n",
    "titles = data['Title']\n",
    "keywords = data['Keywords']\n",
    "abstracts = data['Abstract Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_title_words = []\n",
    "for i in range(len(titles)):\n",
    "    all_title_words = all_title_words + titles[i].split() + keywords[i].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "all_title_words = list(dict.fromkeys(all_title_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop words\n",
    "stop_words = ['a', 'an', 'and', 'the', 'by', 'in', 'on', 'for', 'about', 'we', 'can', 'is', 'are', 'it', 'or', 'of', 'at', \n",
    "              'to', 'how', 'up', 'was', 'were', 'so', 'this', 'that', 'there', 'be', 'some', 'very', 'every', \n",
    "              'all', 'which', 'here', 'where', 'who', '-', 'under', 'with', 'without','same', 'one', \n",
    "             'based','using', 'study', 'problem', 'address','applied','cross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solvi', 'gener', 'share', 'mathe', 'algor', 'parti', 'formu', 'simul', 'annea', 'mutat', 'strat', 'bi-ob', 'optim', 'model', 'three', 'human', 'relie', 'chain', 'type', 'keywo', 'relay', 'full', 'truck', 'freig', 'trans', 'auton', 'route', 'short', 'dista', 'trave', 'predi', 'conta', 'water', 'traff', 'unite', 'barge', 'shipp', 'inlan', 'marit', 'suppl', 'resil', 'asses', 'lared', 'port', 'entry', 'durin', 'covid', 'pande', 'queue', 'theor', 'littl', 'p-ell', 'cover', 'drone', 'deliv', 'netwo', 'desig', 'facil', 'locat', 'area', 'ellip', 'np-ha', 'triti', 'analy', 'mini-', 'store', 'chara', 'barra', '(colo', 'logis', 'retai', 'data', 'minin', 'devel', 'neckl', 'float', 'life-', 'devic', 'produ', 'plan', 'innov', 'plann', 'susta', 'deep', 'reinf', 'learn', 'inven', 'peris', 'quant', 'disco', 'contr', 'manag', 'deman', 'disru', 'signa', 'track', 'inter', 'south', 'regio', 'u.s.', 'prici', 'decis', 'assor', 'neste', 'logit', 'choic', 'multi', 'newsv', 'autom', 'indus', 'food', 'crop', 'focus', 'spoil', 'posth', 'stora', 'losse', 'agrif', 'syste', 'middl', 'mile', 'conso', 'maxim', 'profi', 'throu', 'flexi', 'lead', 'times', 'servi', 'e-com', 'local', 'searc', 'assig', 'close', 'test', 'site', 'place', 'resid', 'group', 'stude', 'shall', 'prese', 'high', 'schoo', 'stand', 'alloc', 'capac', 'addre', 'insec', 'partn', 'agenc', 'opera', 'hours', 'commu', 'resea', 'engin', 'appli', 'agric', 'deter', 'signi', 'facto', 'influ', 'machi', 'techn', 'inacc', 'recor', 'perfo', 'impac', 'modul', 'conti', 'parce', 'physi', 'provi', 'fuzzy', 'routi', 'probl', 'case', 'combi', 'heuri', 'blood', 'bende', 'decom', 'robus', 'meta-', 'testb', 'reser', 'async', 'fleet', 'proto', 'proce', 'wareh', 'intra', 'paral', 'unity', 'hyper', 'k-sho', 'paths', 'branc', 'digit', 'twin', 'frame', 'disas', 'housi', 'assis', 'uncer', 'stoch', 'data-', 'seapo', 'enhan', 'progr', 'consi', 'vehic', 'large', 'size', 'vesse', 'minim', 'costs', 'offsh', 'wind', 'farms', 'farm', 'cost', 'integ', 'rise', 'priva', 'brand', 'persp', 'natio', 'quali', 'perce', 'decon', 'unman', 'aircr', 'hexag', 'tesse', 'path', 'uavs’', 'rescu', 'irreg', 'windy', 'condi', 'aeria', 'grid-', 'aucti', 'selec', 'order', 'procu', 'bank', 'respo', 'natur', 'hunge', 'non-p', 'organ', 'colla', 'prepo', 'dynam', 'emerg', 'pre-p', 'scena', 'distr', 'metho', 'preli', '3d-pr', 'shipb', 'marin', 'debri', 'detec', 'compl', 'time-', 'post-', 'sched', 'volun', 'resou', 'const', 'lagra', 'relax', 'colum', 'banks', 'effic', 'equit', 'inves', 'vulne', 'indic', 'conte', 'surve', 'dedic', 'lane', 'us-me', 'borde', 'cross', 'carri', 'hiera', 'on-ti', 'deplo', 'direc', 'time', 'windo', 'batte', 'repla', 'mixed', 'requi', 'energ', 'consu', 'fulfi', 'omnic', 'retur', 'elect', 'heter', 'recha', 'diver', 'charg', 'types', 'soft', 'saudi', 'arabi', 'swot', 'block', 'reloc', 'degre', 'freed', 'clean', 'move', 'look-', 'hybri', 'conge', 'equil', 'cyber', 'chang', 'stake', 'expla', 'stagi', 'areas', 'hurri', 'clust', 'ageni', 'singl', 'two-s', 'impro', 'two-p', 'envir', 'marko', 'mappi', 'enabl', 'carbo', 'loop', 'objec', 'p-hub', 'linea', 'reman', 'risk', 'twins', 'appro', 'makin', 'sense', 'addit', 'manuf', 'intel', 'rfid', 'senso', 'infor', 'stati']\n"
     ]
    }
   ],
   "source": [
    "# remove stop words, keep only stem of long words\n",
    "title_words = []\n",
    "for i in range(len(all_title_words)):\n",
    "    this_word = all_title_words[i].lower()\n",
    "    if this_word not in stop_words and len(this_word) > 3:\n",
    "        if len(this_word) > 5:\n",
    "            title_words = title_words + [this_word[0:5]]\n",
    "        else:\n",
    "            title_words = title_words + [this_word]\n",
    "# dedup one more time\n",
    "title_words = list(dict.fromkeys(title_words))\n",
    "print(title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the whole feature matrix\n",
    "title_words_freq = [0 for ij in range(len(title_words))]\n",
    "for i in range(len(titles)):\n",
    "    this_doc = (titles[i] + keywords[i] + abstracts[i]).split()\n",
    "    this_doc_words = []\n",
    "    for j in range(len(this_doc)):\n",
    "        this_word = this_doc[j].lower()\n",
    "        if this_word not in stop_words and len(this_word) > 3:\n",
    "            if len(this_word) > 5:\n",
    "                this_word = this_word[0:5]\n",
    "            this_doc_words = this_doc_words + [this_word]\n",
    "    this_doc_words = list(dict.fromkeys(this_doc_words))  # dedup\n",
    "    for j in range(len(title_words)):\n",
    "        for k in range(len(this_doc_words)):\n",
    "            if this_doc_words[k] == title_words[j]:\n",
    "                title_words_freq[j] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_freq = pd.DataFrame({\"stem\":title_words, \"freq\":title_words_freq})\n",
    "stem_freq = stem_freq.sort_values(by = \"freq\",ascending=False)\n",
    "stem_freq.to_csv(\"stem_freq_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now open the stem_freq_all.csv, eyeball all entries, and hand pick useful ones by adding a pick column\n",
    "# Set the pick value to 1 for picked entries, save as stem_freq_all_pick.csv\n",
    "# Then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand pick key words\n",
    "stem_pick = pd.read_csv(\"stem_freq_all_pick.csv\")\n",
    "title_words = list(stem_pick.loc[stem_pick['pick'] == 1, 'stem'])\n",
    "feature_matrix = np.zeros((len(titles),len(title_words)))\n",
    "feature_weight = [1 for i in range(len(title_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the whole feature matrix\n",
    "for i in range(len(titles)):\n",
    "    this_doc = (titles[i] + keywords[i] + abstracts[i]).split()\n",
    "    this_doc_words = []\n",
    "    for j in range(len(this_doc)):\n",
    "        this_word = this_doc[j].lower()\n",
    "        if this_word not in stop_words and len(this_word) > 3:\n",
    "            if len(this_word) > 5:\n",
    "                this_word = this_word[0:5]\n",
    "            this_doc_words = this_doc_words + [this_word]\n",
    "    this_doc_words = list(dict.fromkeys(this_doc_words))  # dedup\n",
    "    for j in range(len(title_words)):\n",
    "        for k in range(len(this_doc_words)):\n",
    "            if this_doc_words[k] == title_words[j]:\n",
    "                feature_matrix[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 98)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the doc-doc similarity matrix\n",
    "simi_matrix = np.zeros((len(titles),len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance matrix (upper triangular)\n",
    "for i in range(len(titles)):\n",
    "    for j in range(i+1, len(titles)-1):\n",
    "        sij = np.multiply(feature_matrix[i,:], feature_matrix[j,:])\n",
    "        sij = np.multiply(sij, feature_weight)\n",
    "        simi_matrix[i,j] = np.sum(sij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 2., ..., 1., 1., 0.],\n",
       "       [0., 0., 2., ..., 3., 0., 0.],\n",
       "       [0., 0., 0., ..., 2., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the doc-to-doc similarity matrix, we can run an optimization model to group abstracts \n",
    "# Constraints: each session must have no more than 4 talks, fill all four slots if possible\n",
    "# The score of a session is the sum of the pairwise similarity values of all talks placed in the session\n",
    "# Objective: maximize the total score of the track (all sessions)\n",
    "# This is a quadratic assignment problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much time do we give the solver?\n",
    "reslim = 15*60  # 15 minutes\n",
    "solver = 'cplex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a GAMS model\n",
    "with open(\"assign.gms\",\"w\") as f:\n",
    "    f.write(\"option reslim = \" + str(reslim) + \";\\n\")\n",
    "    f.write(\"option miqcp = \" + solver + \";\\n\")\n",
    "    f.write(\"set i /1*\" + str(len(titles)) +\"/;\\n\")\n",
    "    f.write(\"set g /1*\" + str(int(np.ceil(len(titles)/ 4))) + \"/;\\n\")\n",
    "    f.write(\"alias(i,j,k);\\nparameter s(i,j);\\n\")\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)-1):\n",
    "            f.write(\"s('\" + str(i+1) + \"','\" + str(j+1) + \"') = \" + str(simi_matrix[i,j]) + \";\\n\")\n",
    "    model_str = '''\n",
    "binary variables\n",
    "x(i,g) 1 if talk i is in session g\n",
    ";\n",
    "variable group_score(g);\n",
    "variable total_score;\n",
    "equations\n",
    "    eq_group_size(g) each group has at most four talks\n",
    "    eq_score(g) calculate group score\n",
    "    eq_place(i) every talk must be placed in a session\n",
    "    eq_obj calculate objective value\n",
    ";\n",
    "eq_group_size(g)..\n",
    "    sum(i, x(i,g)) =l= 4;\n",
    "eq_place(i)..\n",
    "    sum(g, x(i,g)) =e= 1;\n",
    "eq_score(g)..\n",
    "    group_score(g) =e= sum((i,j)$(ord(i)<ord(j)), s(i,j)*x(i,g)*x(j,g));\n",
    "eq_obj..\n",
    "    total_score =e= sum(g, group_score(g));\n",
    "model assign /eq_group_size, eq_place, eq_score, eq_obj/;\n",
    "solve assign maximize total_score using miqcp;\n",
    "parameter result(i);\n",
    "loop((i,g)$x.l(i,g),\n",
    "    result(i) = ord(g);\n",
    ");\n",
    "display result;\n",
    "\n",
    "file f /'sol.txt'/;\n",
    "put f;\n",
    "loop(i,\n",
    "    put (ord(i)-1):0:0 ' ' (result(i)-1):0:0 /;\n",
    ")\n",
    "putclose;\n",
    "\n",
    "    '''\n",
    "    f.write(model_str)\n",
    "    f.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gams', 'assign.gms'], returncode=0)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the GAMS model\n",
    "import subprocess\n",
    "subprocess.run([\"gams\", \"assign.gms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the GAMS solution\n",
    "sol = pd.read_csv(\"sol.txt\", sep = \" \", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract ID</th>\n",
       "      <th>Session ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>15</td>\n",
       "      <td>Solving the general share-a-ride problem by a ...</td>\n",
       "      <td>matheuristic\\ngeneral share-a-ride problem\\nse...</td>\n",
       "      <td>\\nThis research evaluates the General Share-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3250</td>\n",
       "      <td>4</td>\n",
       "      <td>A Bi-Objective Optimization Model for a Three-...</td>\n",
       "      <td>TYPE NEW KEYWORD HERE</td>\n",
       "      <td>\\nThe unpredictable nature and global impact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3533</td>\n",
       "      <td>7</td>\n",
       "      <td>Relay Model for Full Truckload Freight Transpo...</td>\n",
       "      <td>Relay\\nSimulation\\nTrucking</td>\n",
       "      <td>\\nThe driver retention problem in the commerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3539</td>\n",
       "      <td>12</td>\n",
       "      <td>Optimizing Autonomous Trucking Routes for Shor...</td>\n",
       "      <td>Autonomous\\nOptimization\\nTrucking\\nShort Dist...</td>\n",
       "      <td>\\nAutonomous trucking is an innovative technol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>Predicting Container-on-Barge Waterway Traffic...</td>\n",
       "      <td>Barge Transportation\\nContainer Shipping\\nCont...</td>\n",
       "      <td>\\nContainer-on-Barge (COB) employs barges to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3430</td>\n",
       "      <td>4</td>\n",
       "      <td>Resiliency assessment of supply chain system d...</td>\n",
       "      <td>Resiliency\\nsupply chain\\nMarkovian process</td>\n",
       "      <td>\\nThe effect of changing the environmental con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1159</td>\n",
       "      <td>2</td>\n",
       "      <td>Blockchain Technology and Supply Chain Mapping...</td>\n",
       "      <td>Supply Chain Management\\nSupply Chain Mapping\\...</td>\n",
       "      <td>\\nCOVID-19 pandemic led supply chain (SC) disr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1984</td>\n",
       "      <td>10</td>\n",
       "      <td>A Carbon-Conscious Closed Loop Multi Objective...</td>\n",
       "      <td>Closed Loop Supply Chain\\nSustainability\\nMixe...</td>\n",
       "      <td>\\nWith increasing demand for environmentally-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2308</td>\n",
       "      <td>9</td>\n",
       "      <td>Supply Chain Risk Management and Chain Resilience</td>\n",
       "      <td>supply chain risk\\nchain resilience\\nrisk mana...</td>\n",
       "      <td>\\nThe supply chain risk can be expressed as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3772</td>\n",
       "      <td>11</td>\n",
       "      <td>Digital Twins and Digital Supply Chain Managem...</td>\n",
       "      <td>additive manufacturing\\nIntelligent transporta...</td>\n",
       "      <td>\\nFueled by the globalization of trade and the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Abstract ID  Session ID  \\\n",
       "0          1101          15   \n",
       "1          3250           4   \n",
       "2          3533           7   \n",
       "3          3539          12   \n",
       "4          2024           1   \n",
       "..          ...         ...   \n",
       "58         3430           4   \n",
       "59         1159           2   \n",
       "60         1984          10   \n",
       "61         2308           9   \n",
       "62         3772          11   \n",
       "\n",
       "                                                Title  \\\n",
       "0   Solving the general share-a-ride problem by a ...   \n",
       "1   A Bi-Objective Optimization Model for a Three-...   \n",
       "2   Relay Model for Full Truckload Freight Transpo...   \n",
       "3   Optimizing Autonomous Trucking Routes for Shor...   \n",
       "4   Predicting Container-on-Barge Waterway Traffic...   \n",
       "..                                                ...   \n",
       "58  Resiliency assessment of supply chain system d...   \n",
       "59  Blockchain Technology and Supply Chain Mapping...   \n",
       "60  A Carbon-Conscious Closed Loop Multi Objective...   \n",
       "61  Supply Chain Risk Management and Chain Resilience   \n",
       "62  Digital Twins and Digital Supply Chain Managem...   \n",
       "\n",
       "                                              Keyword  \\\n",
       "0   matheuristic\\ngeneral share-a-ride problem\\nse...   \n",
       "1                               TYPE NEW KEYWORD HERE   \n",
       "2                         Relay\\nSimulation\\nTrucking   \n",
       "3   Autonomous\\nOptimization\\nTrucking\\nShort Dist...   \n",
       "4   Barge Transportation\\nContainer Shipping\\nCont...   \n",
       "..                                                ...   \n",
       "58        Resiliency\\nsupply chain\\nMarkovian process   \n",
       "59  Supply Chain Management\\nSupply Chain Mapping\\...   \n",
       "60  Closed Loop Supply Chain\\nSustainability\\nMixe...   \n",
       "61  supply chain risk\\nchain resilience\\nrisk mana...   \n",
       "62  additive manufacturing\\nIntelligent transporta...   \n",
       "\n",
       "                                             Abstract  \n",
       "0   \\nThis research evaluates the General Share-a-...  \n",
       "1   \\nThe unpredictable nature and global impact o...  \n",
       "2   \\nThe driver retention problem in the commerci...  \n",
       "3   \\nAutonomous trucking is an innovative technol...  \n",
       "4   \\nContainer-on-Barge (COB) employs barges to m...  \n",
       "..                                                ...  \n",
       "58  \\nThe effect of changing the environmental con...  \n",
       "59  \\nCOVID-19 pandemic led supply chain (SC) disr...  \n",
       "60  \\nWith increasing demand for environmentally-f...  \n",
       "61  \\nThe supply chain risk can be expressed as a ...  \n",
       "62  \\nFueled by the globalization of trade and the...  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame({\"Abstract ID\":IDs, \"Session ID\":sol.iloc[:,1], \"Title\":titles, \"Keyword\":keywords, \"Abstract\":abstracts})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the common word stems in each session\n",
    "n_sessions = int(np.ceil(len(titles)/ 4))\n",
    "stem2 = []  # stems that are in two or more abstracts\n",
    "stem3 = []  # stems that are in three or more abstracts\n",
    "for g in range(n_sessions):\n",
    "    ids = []\n",
    "    for i in range(len(titles)):\n",
    "        if sol.iloc[i,1] == g:\n",
    "            ids += [i]\n",
    "    this_session_features = feature_matrix[ids,:]\n",
    "    n = this_session_features.shape[0]\n",
    "    common2_idx = []\n",
    "    common3_idx = []\n",
    "    for j in range(len(title_words)):\n",
    "        freq = 0\n",
    "        for k in range(n):\n",
    "            if this_session_features[k,j] == 1:\n",
    "                freq += 1;\n",
    "        if freq >= 2:\n",
    "            common2_idx += [j]\n",
    "        if freq >= 3:\n",
    "            common3_idx += [j]\n",
    "    common_stem2 = ' '.join([title_words[i] for i in common2_idx])\n",
    "    common_stem3 = ' '.join([title_words[i] for i in common3_idx])\n",
    "    stem2 += [common_stem2]\n",
    "    stem3 += [common_stem3]\n",
    "session_summary = pd.DataFrame({\"Session ID\":[i for i in range(n_sessions)], \"stem2\":stem2, \"stem3\":stem3})\n",
    "session_summary.to_csv(\"session_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session ID</th>\n",
       "      <th>stem2</th>\n",
       "      <th>stem3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>netwo deliv integ algor locat simul resil rout...</td>\n",
       "      <td>netwo algor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>netwo const facil plann susta water</td>\n",
       "      <td>plann susta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>netwo pande uncer disru predi</td>\n",
       "      <td>netwo pande predi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>capac plann retai quali priva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>simul resil pande capac disru borde</td>\n",
       "      <td>simul resil disru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>netwo deliv integ const capac disru mixed stoc...</td>\n",
       "      <td>integ const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>netwo deliv integ const locat route capac rout...</td>\n",
       "      <td>deliv route capac routi mixed vehic linea food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>simul fleet marit</td>\n",
       "      <td>simul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>netwo locat cover heuri np-ha</td>\n",
       "      <td>locat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>facil resil uncer disas alloc relie stoch two-...</td>\n",
       "      <td>uncer stoch two-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>netwo integ const route routi mixed linea flee...</td>\n",
       "      <td>integ mixed energ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>netwo manuf uncer hyper</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>deliv integ route manuf truck combi</td>\n",
       "      <td>route truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>deliv manuf retai</td>\n",
       "      <td>deliv manuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>locat servi susta food insec hunge agric</td>\n",
       "      <td>food insec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>const algor route heuri combi</td>\n",
       "      <td>algor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Session ID                                              stem2  \\\n",
       "0            0  netwo deliv integ algor locat simul resil rout...   \n",
       "1            1                netwo const facil plann susta water   \n",
       "2            2                      netwo pande uncer disru predi   \n",
       "3            3                      capac plann retai quali priva   \n",
       "4            4                simul resil pande capac disru borde   \n",
       "5            5  netwo deliv integ const capac disru mixed stoc...   \n",
       "6            6  netwo deliv integ const locat route capac rout...   \n",
       "7            7                                  simul fleet marit   \n",
       "8            8                      netwo locat cover heuri np-ha   \n",
       "9            9  facil resil uncer disas alloc relie stoch two-...   \n",
       "10          10  netwo integ const route routi mixed linea flee...   \n",
       "11          11                            netwo manuf uncer hyper   \n",
       "12          12                deliv integ route manuf truck combi   \n",
       "13          13                                  deliv manuf retai   \n",
       "14          14           locat servi susta food insec hunge agric   \n",
       "15          15                      const algor route heuri combi   \n",
       "\n",
       "                                                stem3  \n",
       "0                                         netwo algor  \n",
       "1                                         plann susta  \n",
       "2                                   netwo pande predi  \n",
       "3                                                      \n",
       "4                                   simul resil disru  \n",
       "5                                         integ const  \n",
       "6   deliv route capac routi mixed vehic linea food...  \n",
       "7                                               simul  \n",
       "8                                               locat  \n",
       "9                                   uncer stoch two-s  \n",
       "10                                  integ mixed energ  \n",
       "11                                                     \n",
       "12                                        route truck  \n",
       "13                                        deliv manuf  \n",
       "14                                         food insec  \n",
       "15                                              algor  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
